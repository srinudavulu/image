{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled6.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7nWPAqyr18eCK8lPLloVF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinudavulu/image/blob/main/Copy_of_Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMs87EeIa1Z8",
        "outputId": "4a42e9e3-a210-4a2f-b686-46c148f7bcb5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlLZ5jFPd_6T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyE-wLk8eBEO"
      },
      "source": [
        "def start_webcam():\n",
        "  js = Javascript('''\n",
        "    async function startWebcam() {\n",
        "\n",
        "      const div = document.createElement('div');\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "\n",
        "      ...\n",
        "      \n",
        "\n",
        "\n",
        "    }\n",
        "    ''')\n",
        "  \n",
        "  display(js)\n",
        "  data = eval_js('startWebcam()')\n",
        "  start_webcam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L84r2EmzcvWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "0e9dd72e-6f23-4589-fab2-8b2231b626ee"
      },
      "source": [
        "var handle Success = function(\"videostream\") \n",
        "  Stream = videostream;\n",
        "  var options = {  \n",
        "    mimeType : 'video/webm;codecs=vp9'  \n",
        "  };            \n",
        "  recorder = new MediaRecorder(stream, options);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('video');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "...\n",
        "...\n",
        "navigator.mediaDevices.getUserMedia({video: true}).then(handleSuccess);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-b568ef97896f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    var handle Success = function(\"videostream\")\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_caLQbSemfu"
      },
      "source": [
        "...\n",
        "\n",
        "# Analyse the video training file \n",
        "face_cascade = cv2.CascadeClassifier(haar_file) \n",
        "webcam = cv2.VideoCapture(video_file_train)  \n",
        "  \n",
        "# Capture the first 30 images of the train video\n",
        "count = 1\n",
        "while count < 30: \n",
        "    if not webcam.isOpened():\n",
        "        print('Unable to load the video file.')\n",
        "        sleep(5)\n",
        "        pass  \n",
        "    (_, im) = webcam.read() \n",
        "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) \n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 4) \n",
        "    for (x, y, w, h) in faces: \n",
        "        cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
        "        face = gray[y:y + h, x:x + w] \n",
        "        face_resize = cv2.resize(face, (width, height)) \n",
        "        cv2.imwrite('% s/% s.png' % (path, count), face_resize) \n",
        "    \n",
        "    count += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifD5KFTfe241"
      },
      "source": [
        "# Train the model from the images with OpenCV Face Recognizer\n",
        "model = cv2.face.LBPHFaceRecognizer_create()\n",
        "model.train(images, lables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEpFUX2hfMJ2"
      },
      "source": [
        "# Use OpenCV Cascade Classifier to detect faces \n",
        "face_cascade = cv2.CascadeClassifier(haar_file) \n",
        "webcam = cv2.VideoCapture(video_file_test)\n",
        "\n",
        "\n",
        "count = 1\n",
        "while count < 30:\n",
        "    ...\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5) \n",
        "    for (x, y, w, h) in faces: \n",
        "        ...\n",
        "        # Try to recognize the face \n",
        "        prediction = model.predict(face_resize) \n",
        "        cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 3) \n",
        "  \n",
        "        ...\n",
        "  \n",
        "    \n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}